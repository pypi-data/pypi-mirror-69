{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Annotations or Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we explore different options to upload annotations in Remo from code. In particular, we can:\n",
    "\n",
    "- add annotations from a file in a format supported by remo\n",
    "- add annotations from code, which enables uploading annotations or model predictions from any input format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by creating a dataset and populating it with some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import remo\n",
    "import os\n",
    "import pandas as pd\n",
    "remo.set_viewer('jupyter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring data - completed                                                                           \n",
      "Processing data - completed                                                                          \n",
      "Data upload completed\n",
      "Open http://localhost:8123/datasets/14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            id=\"remo_frame_3ff34585-372b-452f-be9c-7b274efe530b\"\n",
       "            width=\"100%\"\n",
       "            height=\"100px\"\n",
       "            src=\"http://localhost:8123/datasets/14?allheadless\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        <script type=\"text/javascript\">\n",
       "            (function () {\n",
       "                const iframe = document.getElementById(\"remo_frame_3ff34585-372b-452f-be9c-7b274efe530b\");\n",
       "                let timeout, delay = 100;\n",
       "            \n",
       "                const setHeight = () => {\n",
       "                  const width = iframe.clientWidth;\n",
       "                  iframe.style.height = (width * screen.height / screen.width) * 0.8 + 'px';\n",
       "                }\n",
       "                window.addEventListener(\"resize\", () => {\n",
       "                    clearTimeout(timeout);\n",
       "                  // start timing for event \"completion\"\n",
       "                  timeout = setTimeout(setHeight, delay);\n",
       "                });\n",
       "                setHeight();\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = ['https://remo-scripts.s3-eu-west-1.amazonaws.com/open_images_sample_dataset.zip']\n",
    "my_dataset = remo.create_dataset(name = 'D1', urls = urls)\n",
    "my_dataset.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations from file supported by remo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To add annotations from a supported file format, we can pass the file via `dataset.add_data`**\n",
    "\n",
    "Remo automatically parses annotation files in a variety of formats (such as Pascal XML, CoCo JSON, Open Images CSV, etc). You can read more about file formats supported by remo in [our documentation](https://remo.ai/docs/annotation-formats/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As an example, let's add some annotations for an Object Detection task from a CSV file with encoded classes**\n",
    "\n",
    "In this case, annotations are stored in a CSV file in a format already supported by Remo. Class labels were encoded using [GoogleKnowledgeGraph](https://developers.google.com/knowledge-graph). Remo automatically detects the class encoding and translates it into the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ImageID', 'Source', 'LabelName', 'Confidence', 'XMin', 'XMax', 'YMin',\n",
       "       'YMax', 'IsOccluded', 'IsTruncated', 'IsGroupOf', 'IsDepiction',\n",
       "       'IsInside'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_files=[os.getcwd() + '/assets/open_sample.csv']\n",
    "\n",
    "df = pd.read_csv(annotation_files[0])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring data - completed                                                                           \n",
      "Processing data - completed                                                                          \n",
      "Data upload completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'session_id': '810e23ad-ff63-42a9-89ed-400fbb7d4fc0',\n",
       " 'created_at': '2020-05-29T13:56:17.832956Z',\n",
       " 'dataset': {'id': 14, 'name': 'D1'},\n",
       " 'status': 'done',\n",
       " 'substatus': '',\n",
       " 'images': {'pending': 0,\n",
       "  'total': 0,\n",
       "  'successful': 0,\n",
       "  'failed': 0,\n",
       "  'errors': []},\n",
       " 'annotations': {'pending': 0,\n",
       "  'total': 1,\n",
       "  'successful': 1,\n",
       "  'failed': 0,\n",
       "  'errors': []},\n",
       " 'errors': [],\n",
       " 'uploaded': {'total': {'items': 0, 'size': 0, 'human_size': '0 b'},\n",
       "  'images': {'items': 0, 'size': 0, 'human_size': '0 b'},\n",
       "  'annotations': {'items': 0, 'size': 0, 'human_size': '0 b'},\n",
       "  'archives': {'items': 0, 'size': 0, 'human_size': '0 b'}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.add_data(local_files=annotation_files, annotation_task = 'Object detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see annotation statistics, explore the dataset and further leverage Remo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AnnotationSet ID': 44,\n",
       "  'AnnotationSet name': 'Object detection',\n",
       "  'n_images': 9,\n",
       "  'n_classes': 15,\n",
       "  'n_objects': 84,\n",
       "  'top_3_classes': [{'name': 'Fruit', 'count': 27},\n",
       "   {'name': 'Sports equipment', 'count': 12},\n",
       "   {'name': 'Human arm', 'count': 7}],\n",
       "  'creation_date': None,\n",
       "  'last_modified_date': '2020-05-29T13:56:05.883892Z'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.get_annotation_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/datasets/14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            id=\"remo_frame_5ce1af59-b3aa-463e-a754-71740ffb75df\"\n",
       "            width=\"100%\"\n",
       "            height=\"100px\"\n",
       "            src=\"http://localhost:8123/datasets/14?allheadless\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        <script type=\"text/javascript\">\n",
       "            (function () {\n",
       "                const iframe = document.getElementById(\"remo_frame_5ce1af59-b3aa-463e-a754-71740ffb75df\");\n",
       "                let timeout, delay = 100;\n",
       "            \n",
       "                const setHeight = () => {\n",
       "                  const width = iframe.clientWidth;\n",
       "                  iframe.style.height = (width * screen.height / screen.width) * 0.8 + 'px';\n",
       "                }\n",
       "                window.addEventListener(\"resize\", () => {\n",
       "                    clearTimeout(timeout);\n",
       "                  // start timing for event \"completion\"\n",
       "                  timeout = setTimeout(setHeight, delay);\n",
       "                });\n",
       "                setHeight();\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_added_annotation.jpeg](assets/dataset_added_annotation.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations from code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also easily to add annotations from code via the `Annotation` object**\n",
    "\n",
    "\n",
    "This can be useful to:\n",
    "- visualize model predictions\n",
    "- upload annotations from any custom file format\n",
    "- create an active learning workflow\n",
    "\n",
    "As an example, let's see how we can add annotations to a specific image using `add_annotations()` method of the dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 100% - 1/1 - elapsed 0:00:00.001000 - speed: 1000.00 img / s, ETA: 0:00:00\n",
      "Acquiring data - completed                                                                           \n",
      "Processing data - completed                                                                          \n",
      "Data upload completed\n"
     ]
    }
   ],
   "source": [
    "image_name = '000a1249af2bc5f0.jpg'\n",
    "\n",
    "annotations = []\n",
    "\n",
    "annotation = remo.Annotation()\n",
    "annotation.img_filename = image_name\n",
    "annotation.classes='Human hand'\n",
    "annotation.bbox=[227, 284, 678, 674]\n",
    "annotations.append(annotation)\n",
    "\n",
    "annotation = remo.Annotation()\n",
    "annotation.img_filename = image_name\n",
    "annotation.classes='Fashion accessory'\n",
    "annotation.bbox=[496, 322, 544,370]\n",
    "annotations.append(annotation)\n",
    "\n",
    "my_dataset.add_annotations(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrieve the picture and visualise it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/image/16244?dataset_id=14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            id=\"remo_frame_c9515ee8-fb6d-4f0d-96db-533a6cbc7ed5\"\n",
       "            width=\"100%\"\n",
       "            height=\"100px\"\n",
       "            src=\"http://localhost:8123/image/16244?dataset_id=14&allheadless\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        <script type=\"text/javascript\">\n",
       "            (function () {\n",
       "                const iframe = document.getElementById(\"remo_frame_c9515ee8-fb6d-4f0d-96db-533a6cbc7ed5\");\n",
       "                let timeout, delay = 100;\n",
       "            \n",
       "                const setHeight = () => {\n",
       "                  const width = iframe.clientWidth;\n",
       "                  iframe.style.height = (width * screen.height / screen.width) * 0.8 + 'px';\n",
       "                }\n",
       "                window.addEventListener(\"resize\", () => {\n",
       "                    clearTimeout(timeout);\n",
       "                  // start timing for event \"completion\"\n",
       "                  timeout = setTimeout(setHeight, delay);\n",
       "                });\n",
       "                setHeight();\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_image = my_dataset.image(image_name)\n",
    "my_image.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_added_annotation.jpeg](assets/added_annotation.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Behind the scenes, Remo organises annotations in Annotation sets. An annotation set is simply a collection of all the annotations of Dataset.**\n",
    "\n",
    "\n",
    "The advantage of grouping annotations in an Annotation Set is that it allows for high-level group operations on all the annotations, such as:\n",
    "- grouping classes together\n",
    "- deleting objects of specific classes\n",
    "- comparing of different annotations (such as ground truth vs prediction, or annotations coming from different annotators)\n",
    "\n",
    "In the examples we have seen before, Remo automatically creates an annotation set and sets it as default. For more control, it's however possible to explicit manipulate Annotation sets objects.\n",
    "\n",
    "To read more about annotation sets, you can check the remo documentation: https://remo.ai/docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
