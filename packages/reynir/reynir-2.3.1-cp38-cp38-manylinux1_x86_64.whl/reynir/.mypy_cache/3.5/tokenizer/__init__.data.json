{".class": "MypyFile", "_fullname": "tokenizer", "is_partial_stub_package": false, "is_stub": false, "names": {".class": "SymbolTable", "Abbreviations": {".class": "SymbolTableNode", "cross_ref": "tokenizer.abbrev.Abbreviations", "kind": "Gdef"}, "ConfigError": {".class": "SymbolTableNode", "cross_ref": "tokenizer.abbrev.ConfigError", "kind": "Gdef"}, "EM_DASH": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready"], "fullname": "tokenizer.EM_DASH", "name": "EM_DASH", "type": {".class": "AnyType", "missing_import_name": "tokenizer.EM_DASH", "source_any": null, "type_of_any": 3}}}, "EN_DASH": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready"], "fullname": "tokenizer.EN_DASH", "name": "EN_DASH", "type": {".class": "AnyType", "missing_import_name": "tokenizer.EN_DASH", "source_any": null, "type_of_any": 3}}}, "KLUDGY_ORDINALS_MODIFY": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready"], "fullname": "tokenizer.KLUDGY_ORDINALS_MODIFY", "name": "KLUDGY_ORDINALS_MODIFY", "type": {".class": "AnyType", "missing_import_name": "tokenizer.KLUDGY_ORDINALS_MODIFY", "source_any": null, "type_of_any": 3}}}, "KLUDGY_ORDINALS_PASS_THROUGH": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready"], "fullname": "tokenizer.KLUDGY_ORDINALS_PASS_THROUGH", "name": "KLUDGY_ORDINALS_PASS_THROUGH", "type": {".class": "AnyType", "missing_import_name": "tokenizer.KLUDGY_ORDINALS_PASS_THROUGH", "source_any": null, "type_of_any": 3}}}, "KLUDGY_ORDINALS_TRANSLATE": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready"], "fullname": "tokenizer.KLUDGY_ORDINALS_TRANSLATE", "name": "KLUDGY_ORDINALS_TRANSLATE", "type": {".class": "AnyType", "missing_import_name": "tokenizer.KLUDGY_ORDINALS_TRANSLATE", "source_any": null, "type_of_any": 3}}}, "TOK": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.TOK", "kind": "Gdef"}, "TP_CENTER": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready"], "fullname": "tokenizer.TP_CENTER", "name": "TP_CENTER", "type": {".class": "AnyType", "missing_import_name": "tokenizer.TP_CENTER", "source_any": null, "type_of_any": 3}}}, "TP_LEFT": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready"], "fullname": "tokenizer.TP_LEFT", "name": "TP_LEFT", "type": {".class": "AnyType", "missing_import_name": "tokenizer.TP_LEFT", "source_any": null, "type_of_any": 3}}}, "TP_NONE": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready"], "fullname": "tokenizer.TP_NONE", "name": "TP_NONE", "type": {".class": "AnyType", "missing_import_name": "tokenizer.TP_NONE", "source_any": null, "type_of_any": 3}}}, "TP_RIGHT": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready"], "fullname": "tokenizer.TP_RIGHT", "name": "TP_RIGHT", "type": {".class": "AnyType", "missing_import_name": "tokenizer.TP_RIGHT", "source_any": null, "type_of_any": 3}}}, "TP_WORD": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready"], "fullname": "tokenizer.TP_WORD", "name": "TP_WORD", "type": {".class": "AnyType", "missing_import_name": "tokenizer.TP_WORD", "source_any": null, "type_of_any": 3}}}, "Tok": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.Tok", "kind": "Gdef"}, "__author__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "tokenizer.__author__", "name": "__author__", "type": "builtins.str"}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "tokenizer.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "tokenizer.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "tokenizer.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "tokenizer.__package__", "name": "__package__", "type": "builtins.str"}}, "absolute_import": {".class": "SymbolTableNode", "cross_ref": "__future__.absolute_import", "kind": "Gdef"}, "correct_spaces": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.correct_spaces", "kind": "Gdef"}, "detokenize": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.detokenize", "kind": "Gdef"}, "mark_paragraphs": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.mark_paragraphs", "kind": "Gdef"}, "normalized_text": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.normalized_text", "kind": "Gdef"}, "normalized_text_from_tokens": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.normalized_text_from_tokens", "kind": "Gdef"}, "paragraphs": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.paragraphs", "kind": "Gdef"}, "parse_tokens": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.parse_tokens", "kind": "Gdef"}, "split_into_sentences": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.split_into_sentences", "kind": "Gdef"}, "text_from_tokens": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.text_from_tokens", "kind": "Gdef"}, "tokenize": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.tokenize", "kind": "Gdef"}, "tokenize_without_annotation": {".class": "SymbolTableNode", "cross_ref": "tokenizer.tokenizer.tokenize_without_annotation", "kind": "Gdef"}}, "path": "/home/villi/github/Tokenizer/src/tokenizer/__init__.py"}