# AUTOGENERATED! DO NOT EDIT! File to edit: 03_pd.ipynb (unless otherwise specified).

__all__ = ['bq_project_id', 'df_to_gbq']

# Cell
#export
import os
import pandas as pd
from dotenv import load_dotenv
from google.cloud import bigquery
from .schema import get_schema, df_to_bq_schema, schema_diff, update_bq_schema, update_df_schema
from .utils import does_table_exist

bq_project_id = os.getenv('BQ_PROJECT_ID')

# Cell


def df_to_gbq(df: pd.DataFrame, destination_table: str, project_id: str, if_exists: str = 'append', print_info: bool = True) -> pd.DataFrame:
    """
    Save df to BigQuery enforcing schema consistency between df and destination table if it exists.
    """

    table_id = f'{project_id}.{destination_table}'
    bq_client = bigquery.Client()

    # only need to handle schema's if table already exists and if_exists != 'replace'
    if does_table_exist(bq_client, table_id) and if_exists != 'replace' :

        old_schema = get_schema(table_id)
        new_schema = df_to_bq_schema(df)
        diffs = schema_diff(old_schema, new_schema)

        # update the table schema in BigQuery
        update_bq_schema(bq_client, table_id, diffs, print_info=print_info)

        # update the df schema to be as expected by BigQuery
        df = update_df_schema(bq_client, table_id, diffs, df, print_info=print_info)

    # load to BigQuery
    df.to_gbq(destination_table, project_id=project_id, if_exists=if_exists)

    return df

