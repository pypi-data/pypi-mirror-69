Metadata-Version: 2.1
Name: reagent
Version: 0.1
Summary: Facebook RL
Home-page: https://github.com/facebookresearch/ReAgent
Author: Facebook
License: BSD 3-Clause License
Platform: UNKNOWN
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: click (>=7.0)
Requires-Dist: cloudpickle (~=1.2.0)
Requires-Dist: numpy (>=1.17.2)
Requires-Dist: pandas (>=1.0.3)
Requires-Dist: pydantic (>=1.4)
Requires-Dist: torch
Requires-Dist: tqdm (>=4.46.0)
Requires-Dist: petastorm (>=0.9.0)
Requires-Dist: parameterized (>=0.7.4)
Requires-Dist: pyspark (>=2.4.5)
Requires-Dist: ruamel.yaml (>=0.15.99)
Requires-Dist: scipy (>=1.3.1)
Requires-Dist: tensorboard (>=1.14)
Requires-Dist: scikit-learn (>=0.20.0)
Requires-Dist: xgboost (==0.90)
Provides-Extra: gym
Requires-Dist: gym[atari,box2d,classic_control] ; extra == 'gym'
Requires-Dist: gym-minigrid ; extra == 'gym'
Requires-Dist: recsim-no-tf ; extra == 'gym'
Provides-Extra: test
Requires-Dist: coverage (>=5.1) ; extra == 'test'
Requires-Dist: pytest-xdist (==1.30.0) ; extra == 'test'
Requires-Dist: pytest (==5.3) ; extra == 'test'
Requires-Dist: spark-testing-base (==0.10.0) ; extra == 'test'
Requires-Dist: pytest-cov ; extra == 'test'

![Banner](logo/reagent_banner.png)
### Applied Reinforcement Learning @ Facebook
[![License](https://img.shields.io/badge/license-BSD%203--Clause-brightgreen)](LICENSE)
[![CircleCI](https://circleci.com/gh/facebookresearch/ReAgent/tree/master.svg?style=shield)](https://circleci.com/gh/facebookresearch/ReAgent/tree/master)
[![codecov](https://codecov.io/gh/facebookresearch/ReAgent/branch/master/graph/badge.svg)](https://codecov.io/gh/facebookresearch/ReAgent)
---

#### Overview
ReAgent is an open source end-to-end platform for applied reinforcement learning (RL) developed and used at Facebook. ReAgent is built in Python and uses PyTorch for modeling and training and TorchScript for model serving. The platform contains workflows to train popular deep RL algorithms and includes data preprocessing, feature transformation, distributed training, counterfactual policy evaluation, and optimized serving. For more detailed information about ReAgent see the white paper [here](https://research.fb.com/publications/horizon-facebooks-open-source-applied-reinforcement-learning-platform/).

The platform was once named "Horizon" but we have adopted the name "ReAgent" recently to emphasize its broader scope in decision making and reasoning.

#### Algorithms Supported
- Discrete-Action [DQN](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)
- Parametric-Action DQN
- [Double DQN](https://arxiv.org/abs/1509.06461), [Dueling DQN](https://arxiv.org/abs/1511.06581), [Dueling Double DQN](https://arxiv.org/abs/1710.02298)
- Distributional RL: [C51](https://arxiv.org/abs/1707.06887) and [QR-DQN](https://arxiv.org/abs/1710.10044)
- [Twin Delayed DDPG](https://arxiv.org/abs/1802.09477) (TD3)
- [Soft Actor-Critic](https://arxiv.org/abs/1801.01290) (SAC)

#### Installation
ReAgent can be installed via. Docker or manually. Detailed instructions on how to install ReAgent can be found [here](docs/installation.rst).

#### Usage
Detailed instructions on how to use ReAgent Models can be found [here](docs/usage.rst).

The ReAgent Serving Platform (RASP) tutorial is available [here](docs/rasp_tutorial.rst).

#### License
ReAgent is released under a BSD 3-Clause license.  Find out more about it [here](LICENSE).

#### Citing
@article{gauci2018horizon,
  title={Horizon: Facebook's Open Source Applied Reinforcement Learning Platform},
  author={Gauci, Jason and Conti, Edoardo and Liang, Yitao and Virochsiri, Kittipat and Chen, Zhengxing and He, Yuchen and Kaden, Zachary and Narayanan, Vivek and Ye, Xiaohui},
  journal={arXiv preprint arXiv:1811.00260},
  year={2018}
}


