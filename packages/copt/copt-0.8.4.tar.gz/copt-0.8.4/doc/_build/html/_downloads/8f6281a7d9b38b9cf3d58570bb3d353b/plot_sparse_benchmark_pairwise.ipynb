{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nBenchmark of Pairwise Frank-Wolfe variants for sparse logistic regression\n=========================================================================\n\nSpeed of convergence of different Frank-Wolfe variants on various\nproblems with a logistic regression loss (:meth:`copt.utils.LogLoss`)\nand a L1 ball constraint (:meth:`copt.utils.L1Ball`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport copt as cp\n\n# .. datasets and their loading functions ..\n# .. last value si the regularization parameter ..\n# .. which has been chosen to give 10% feature sparsity ..\ndatasets = (\n    {\n        \"name\": \"RCV1\",\n        \"loader\": cp.datasets.load_rcv1,\n        \"alpha\": 1e3,\n        \"max_iter\": 5000,\n        \"f_star\": 0.3114744279728717,\n    },\n    {\n        \"name\": \"gisette\",\n        \"loader\": cp.datasets.load_gisette,\n        \"alpha\": 1e4,\n        \"max_iter\": 5000,\n        \"f_star\": 2.293654421822428,\n    },\n    {\n        \"name\": \"madelon\",\n        \"loader\": cp.datasets.load_madelon,\n        \"alpha\": 1e4,\n        \"max_iter\": 5000,\n        \"f_star\": 0.0,\n    },\n    {\n        \"name\": \"covtype\",\n        \"loader\": cp.datasets.load_covtype,\n        \"alpha\": 1e4,\n        \"max_iter\": 5000,\n        \"f_star\": 0,\n    },\n)\n\n\nvariants_fw = [\n    [\"adaptive\", \"adaptive step-size\", \"s\"],\n    [\"DR\", \"Lipschitz step-size\", \"<\"],\n]\n\nfor d in datasets:\n    plt.figure()\n    print(\"Running on the %s dataset\" % d[\"name\"])\n\n    X, y = d[\"loader\"]()\n    print(X.shape)\n    n_samples, n_features = X.shape\n\n    l1_ball = cp.utils.L1Ball(d[\"alpha\"])\n    f = cp.utils.LogLoss(X, y)\n    x0 = np.zeros(n_features)\n    x0[0] = d[\"alpha\"]  # start from a (random) vertex\n\n    for step, label, marker in variants_fw:\n\n        cb = cp.utils.Trace(f)\n        sol = cp.minimize_frank_wolfe(\n            f.f_grad,\n            x0,\n            l1_ball.lmo_pairwise,\n            callback=cb,\n            step=step,\n            lipschitz=f.lipschitz,\n            max_iter=d[\"max_iter\"],\n            verbose=True,\n            tol=0,\n        )\n\n        plt.plot(\n            cb.trace_time,\n            np.array(cb.trace_fx) - d[\"f_star\"],\n            label=label,\n            marker=marker,\n            markevery=10,\n        )\n\n    print(\"Sparsity of solution: %s\" % np.mean(np.abs(sol.x) > 1e-8))\n    print(f(sol.x))\n    plt.legend()\n    plt.xlabel(\"Time (in seconds)\")\n    plt.ylabel(\"Objective function\")\n    plt.title(d[\"name\"])\n    plt.tight_layout()  # otherwise the right y-label is slightly clipped\n    #    plt.xlim((0, 0.7 * cb.trace_time[-1]))  # for aesthetics\n    plt.grid()\n    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}